{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will specifically use data from the Allen Insitute for Neural Dynamics and show how we can leverage CEBRA to analyse our in-house data. Here we will check if we can distinguish between trials where the mouse licked right vs trials where it licked left in the dynamic foraging task. We also tried to check if we can s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os # my addtion\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import solve_ivp\n",
    "import cebra.data\n",
    "import torch\n",
    "import cebra.integrations\n",
    "import cebra.datasets\n",
    "from cebra import CEBRA\n",
    "import torch\n",
    "import pickle\n",
    "import cebra_pack.cebra_utils as cp\n",
    "\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load the Data\n",
    "\n",
    "Here we load data from the Fibre Photometry pipeline of 4 Neuromodulators (DA, 5HT, ACh, NE) recorded in the Nucleus Acumbens region. The main neural data will be in the form of dF_F traces of these 4 Neuromodulators (NMs). These will be stored in a 2D array, 'all_nms'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe that contains data from 1 session\n",
    "df_trials_ses = pickle.load(open('../data/CO data/df.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bit_code', 'ses_idx', 'rpe', 'left_action_value', 'right_action_value',\n",
       "       'licks L', 'licks R', 'Lick L (raw)', 'Lick R (raw)', 'trial', 'reward',\n",
       "       'choice', 'go_cue_absolute_time', 'go_cue', 'choice_time',\n",
       "       'reward_time', 'onset', 'NM', 'NM_name', 'region', 'last_value_NM',\n",
       "       'overlap_index', 'NM_no_overlap', 'bins_mids', 'bins_mids_no_overlap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials_ses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = df_trials_ses['licks L'].iloc[:1765].values\n",
    "l2 = df_trials_ses['licks L'].iloc[3530:5295].values\n",
    "np.sum(l1-l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>licks L</th>\n",
       "      <th>licks R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7060 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      licks L  licks R\n",
       "0        26.0      0.0\n",
       "1        10.0      0.0\n",
       "2         2.0      0.0\n",
       "3         2.0      0.0\n",
       "4         1.0      0.0\n",
       "...       ...      ...\n",
       "1760      1.0      0.0\n",
       "1761      3.0      0.0\n",
       "1762      2.0      0.0\n",
       "1763      1.0      0.0\n",
       "1764      1.0      0.0\n",
       "\n",
       "[7060 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials_ses[['licks L', 'licks R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>licks L</th>\n",
       "      <th>licks R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7060.000000</td>\n",
       "      <td>7060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.309915</td>\n",
       "      <td>2.229462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.377764</td>\n",
       "      <td>3.430823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           licks L      licks R\n",
       "count  7060.000000  7060.000000\n",
       "mean      1.309915     2.229462\n",
       "std       2.377764     3.430823\n",
       "min       0.000000     0.000000\n",
       "25%       0.000000     0.000000\n",
       "50%       0.000000     1.000000\n",
       "75%       1.000000     2.000000\n",
       "max      26.000000    21.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials_ses[['licks L', 'licks R']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([117,   1]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_trials_ses['Lick L (raw)'].iloc[7], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: There's 1765 trials in this data frame (the indices are repeated over each neuromodulator)\n",
    "all information is in the first 1765 rows so we'll consider those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dictionary containing the traces\n",
    "traces = pickle.load(open('../data/CO data/traces.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trace times\n",
    "trace_times = np.load('../data/CO data/Trace times.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the choice time \n",
    "choice_times = df_trials_ses['choice_time'][0:n_trials].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218572, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the traces into one 2D array\n",
    "all_nms = np.array([traces[trace] for trace in traces.keys()])\n",
    "all_nms = np.transpose(all_nms)\n",
    "\n",
    "# change it to an array of floats (previously it was an array of object datatype)\n",
    "all_nms_new = all_nms.astype(np.float64)\n",
    "all_nms_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218572, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218572, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change it to an array of floats (previously it was an array of object datatype)\n",
    "all_nms_new = all_nms.astype(np.float64)\n",
    "all_nms_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([218572, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert it to a tensor (this is probably not necessary but we want it to be as close to the inputs in the previous notebook)\n",
    "all_nms_tensor = torch.from_numpy(all_nms_new)\n",
    "all_nms_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Format data and create the behavioural/auxiliary variables\n",
    "\n",
    "Now let's format the data. We want to view the data in a 1 second window around the choice time at each trial in the session. The hope is that this will make it easy to identify the trials where it chose to lick left and those where it chose to lick right.\n",
    "\n",
    "Each trial will be labelled as rewarded/unrewarded and this will be the behavioural variable we use for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = np.argwhere(df_trials_ses['licks R'] > df_trials_ses['licks L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26., 10.,  2., ...,  2.,  1.,  1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials_ses['licks L'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06288951841359773"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "444/(6616+444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7060"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6616+444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6% of the trials had an equal number of left and right licks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indxs = np.argwhere(df_trials_ses['licks L'] == df_trials_ses['licks R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([184, 240,  20]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_trials_ses['licks L'].to_numpy()[indxs],return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the trials where the number of left and right trials are equal, the number of licks in either direction is either 0,1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to format the NM data into a 1s window around the choice\n",
    "\n",
    "def format_data(neural_data, df, trace_times_, choice_times_ , window=None , window_size=10, n_trials=1765):\n",
    "\n",
    "    # define the number of trials where the mouse made a choice\n",
    "    n_choice_trials = np.unique(np.isnan(choice_times_),return_counts=True)[1][0]\n",
    "\n",
    "    # list to hold all the 1s windows\n",
    "    n_data_window = []\n",
    "\n",
    "    # new trial label\n",
    "    trial_labels = []\n",
    "\n",
    "    # magnitude label (number of licks)\n",
    "    n_licks = []\n",
    "\n",
    "    # loop over all trials\n",
    "    for i in range(0,n_trials):\n",
    "\n",
    "        # skip trials where the animal didn't make a choice (null choice time)\n",
    "        if np.isnan(choice_times_[i]):\n",
    "            continue\n",
    "\n",
    "        # find the index of the closest time to the choice time in the trace_times array \n",
    "        idx = np.abs(trace_times_ - choice_times_[i]).argmin()\n",
    "\n",
    "        # take the previous 10 and/or the next 10 values of the NM data at these indices - 1s window\n",
    "        if window =='before':\n",
    "            n_data_window.append(neural_data[idx-10:idx])\n",
    "\n",
    "        if window == 'after':\n",
    "            n_data_window.append(neural_data[idx:idx+10])\n",
    "\n",
    "        if window == None:\n",
    "            n_data_window.append(neural_data[idx-10:idx+10])\n",
    "\n",
    "        # label the timepoints as left or right choice\n",
    "        if df['licks L'].iloc[i] >= df['licks R'].iloc[i]:\n",
    "            # new trial label\n",
    "            trial_labels.append(1)\n",
    "            n_licks.append(df['licks L'].iloc[i])\n",
    "\n",
    "        elif df['licks R'].iloc[i] > df['licks L'].iloc[i]:\n",
    "            # new trial label\n",
    "            trial_labels.append(0)\n",
    "            n_licks.append(df['licks R'].iloc[i])\n",
    "\n",
    "\n",
    "    # stack the nm data for each trial\n",
    "    nms_HD = np.stack(n_data_window).reshape((n_choice_trials,-1))\n",
    "    # format it into a tensor\n",
    "    nms_HD = torch.from_numpy(nms_HD.astype(np.float64))\n",
    "    print(\"neural tensor shape: \", nms_HD.shape)\n",
    "\n",
    "    # convert trial labels into an array\n",
    "    choice_labels = np.array(trial_labels)\n",
    "    n_licks = np.array(n_licks)\n",
    "    print(\"labels shape: \",choice_labels.shape)\n",
    "    print(\"number of licks:\", n_licks.shape)\n",
    "\n",
    "    return nms_HD, choice_labels, n_licks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural tensor shape:  torch.Size([1717, 80])\n",
      "labels shape:  (1717,)\n",
      "number of licks: (1717,)\n"
     ]
    }
   ],
   "source": [
    "formatted_nms, trial_labels, n_licks = format_data(all_nms,df=df_trials_ses,trace_times_=trace_times, choice_times_=choice_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7cfe33a130>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(n_licks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a behaviour label that gives information on both the direction and how many licks in that direction it took\n",
    "# -- use the 3D array like they did in the hippocampus demo\n",
    "\n",
    "# but first let's start with just whether it licked left or right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 1765 trials in the session, this particular mouse made a choice in 1717 of them. So we will only use those trials. Therefore we have a binary array of shape (1717,) as our behavioural label. The NM data is organized such that we have 20 timesteps for each of the 4 neuromodulators in this 1 second window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Build and train the CEBRA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the maximum number of iterations for training the model\n",
    "max_iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a CEBRA-Time and CEBRA-Behaviour model\n",
    "cebra_time_model = CEBRA(model_architecture='offset10-model-mse',\n",
    "                        batch_size=512,\n",
    "                        learning_rate=3e-4,\n",
    "                        temperature=1,\n",
    "                        output_dimension=3,\n",
    "                        max_iterations=max_iterations,\n",
    "                        distance='euclidean',\n",
    "                        conditional='time',\n",
    "                        device='cuda_if_available',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_behaviour_model = CEBRA(model_architecture='offset10-model-mse',\n",
    "                        batch_size=512,\n",
    "                        learning_rate=3e-4,\n",
    "                        temperature=1,\n",
    "                        output_dimension=3,\n",
    "                        max_iterations=max_iterations,\n",
    "                        distance='euclidean',\n",
    "                        conditional='time_delta',\n",
    "                        device='cuda_if_available',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.8810 neg:  2.8742 total:  3.7552 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:12<00:00, 158.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CEBRA(batch_size=512, conditional=&#x27;time&#x27;, distance=&#x27;euclidean&#x27;,\n",
       "      max_iterations=2000, model_architecture=&#x27;offset10-model-mse&#x27;,\n",
       "      output_dimension=3, temperature=1, time_offsets=10, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CEBRA</label><div class=\"sk-toggleable__content\"><pre>CEBRA(batch_size=512, conditional=&#x27;time&#x27;, distance=&#x27;euclidean&#x27;,\n",
       "      max_iterations=2000, model_architecture=&#x27;offset10-model-mse&#x27;,\n",
       "      output_dimension=3, temperature=1, time_offsets=10, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CEBRA(batch_size=512, conditional='time', distance='euclidean',\n",
       "      max_iterations=2000, model_architecture='offset10-model-mse',\n",
       "      output_dimension=3, temperature=1, time_offsets=10, verbose=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the time model (no labels here)\n",
    "cebra_time_model.fit(formatted_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.3213 neg:  5.7475 total:  6.0687 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:13<00:00, 148.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CEBRA(batch_size=512, conditional=&#x27;time_delta&#x27;, distance=&#x27;euclidean&#x27;,\n",
       "      max_iterations=2000, model_architecture=&#x27;offset10-model-mse&#x27;,\n",
       "      output_dimension=3, temperature=1, time_offsets=10, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CEBRA</label><div class=\"sk-toggleable__content\"><pre>CEBRA(batch_size=512, conditional=&#x27;time_delta&#x27;, distance=&#x27;euclidean&#x27;,\n",
       "      max_iterations=2000, model_architecture=&#x27;offset10-model-mse&#x27;,\n",
       "      output_dimension=3, temperature=1, time_offsets=10, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CEBRA(batch_size=512, conditional='time_delta', distance='euclidean',\n",
       "      max_iterations=2000, model_architecture='offset10-model-mse',\n",
       "      output_dimension=3, temperature=1, time_offsets=10, verbose=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the behaviour model (use the labels here)\n",
    "cebra_behaviour_model.fit(formatted_nms, trial_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Compute and view embeddings\n",
    "\n",
    "Here, we compute the embeddings from the two trained models and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_embedding = cebra_time_model.transform(formatted_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_embedding = cebra_behaviour_model.transform(formatted_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the labels into right and left\n",
    "left = trial_labels==1\n",
    "right = trial_labels==0\n",
    "\n",
    "left = left.flatten()\n",
    "right = right.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values (and their corresponding counts in the labels: (array([False,  True]), array([ 713, 1004]))\n",
      "Embedding (time) shape: (1717, 3)\n",
      "Embedding (behaviour) shape: (1717, 3)\n",
      "Difference between the length of embedding array and the total number of trials: 0\n"
     ]
    }
   ],
   "source": [
    "# sanity check - confirm that there's only two possibilities and that they add up to the total # of trials\n",
    "print('Unique values (and their corresponding counts in the labels:',np.unique(right, return_counts=True))\n",
    "\n",
    "print('Embedding (time) shape:',time_embedding.shape)\n",
    "print('Embedding (behaviour) shape:',behaviour_embedding.shape)\n",
    "\n",
    "print(\"Difference between the length of embedding array and the total number of trials:\",np.sum(time_embedding.shape[0] - np.sum(np.unique(right, return_counts=True)[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8722473360415282, 0.5408450350072361]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get auc scores\n",
    "mean_scores, errors = cp.get_auc([behaviour_embedding, time_embedding], trial_labels=trial_labels)\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'latent 3')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a figure and make the plots\n",
    "fig1 = plt.figure(figsize=(16,4))\n",
    "gs = gridspec.GridSpec(1, 2, figure=fig1)\n",
    "\n",
    "ax1 = fig1.add_subplot(gs[0,0], projection='3d')\n",
    "ax2 = fig1.add_subplot(gs[0,1], projection='3d')\n",
    "axes =[ax1,ax2]\n",
    "\n",
    "for ax in axes:\n",
    "\n",
    "\n",
    "    ax.set_xlabel(\"latent 1\", labelpad=0.01)\n",
    "    ax.set_ylabel(\"latent 2\", labelpad=0.01)\n",
    "    ax.set_zlabel(\"latent 3\", labelpad=0.01)\n",
    "\n",
    "    # Hide X and Y axes label marks\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "    ax.zaxis.set_tick_params(labelright=False)\n",
    "\n",
    "    # Hide X and Y axes tick marks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "\n",
    "# colour maps\n",
    "colours = ['cool', 'plasma']\n",
    "\n",
    "# plot the time embedding \n",
    "cebra.plot_embedding(embedding=time_embedding[left,:], embedding_labels=trial_labels[left],ax=ax1, markersize=2, title='Time embedding', cmap=colours[0])\n",
    "cebra.plot_embedding(embedding=time_embedding[right,:], embedding_labels=trial_labels[right],ax=ax1, markersize=2, title='Time embedding, AUC: 0.56', cmap=colours[1])\n",
    "\n",
    "# plot the behaviour embedding \n",
    "cebra.plot_embedding(embedding=behaviour_embedding[left,:], embedding_labels=trial_labels[left],ax=ax2, markersize=2, title='Behaviour embedding', cmap=colours[0],)\n",
    "cebra.plot_embedding(embedding=behaviour_embedding[right,:], embedding_labels=trial_labels[right],ax=ax2,markersize=2, title='Behaviour embedding, AUC: 0.87',  cmap=colours[1])\n",
    "\n",
    "\n",
    "# Adjust the subplot layout manually\n",
    "#plt.subplots_adjust(left=0.095, right=0.1, top=0.95, bottom=0.05, wspace=0.001)\n",
    "\n",
    "# Adjust the subplot layout manually\n",
    "plt.subplots_adjust(left=0.00001, right=0.55, top=0.95, bottom=0.05, wspace=0.0001)\n",
    "\n",
    "# Use tight_layout with padding to ensure labels are not cut off\n",
    "\n",
    "\n",
    "# Adjust label positions using bbox\n",
    "ax2.set_zlabel(\"latent 3\", labelpad=1, fontsize=10, bbox=dict(facecolor='white', edgecolor='none', pad=0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this pair of embeddings we can see that there is a clustering of the left (light blue) and right (purple) trials when we use CEBRA behaviour. \n",
    "What if we tried using both the (left/right) choice and the number of licks in either direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_licks_ = n_licks.reshape(n_licks.shape[0],-1)\n",
    "right_ = right.reshape(right.shape[0],-1).astype(np.float64)\n",
    "left_ = left.reshape(left.shape[0], -1).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1717, 1)\n",
      "(1717, 1)\n",
      "(1717, 1)\n"
     ]
    }
   ],
   "source": [
    "print(n_licks_.shape)\n",
    "print(right_.shape)\n",
    "print(left_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1717, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arrange the labels like in the hippocampus recordings experiment demo\n",
    "lr_licks = np.concatenate((n_licks_,left_,right_), axis=1)\n",
    "lr_licks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.0509 neg:  5.4406 total:  5.4915 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:13<00:00, 148.49it/s]\n",
      "pos:  0.4388 neg:  5.5478 total:  5.9866 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:14<00:00, 139.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# build, train and compute with the time and behaviour models with this new labels\n",
    "t_embed,b_embed =  cp.build_train_compute(formatted_nms,lr_licks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 21., 26.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lr_licks[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to view the embeddings\n",
    "def view(time_embedding, behaviour_embedding, labels, label_classes, size=5):\n",
    " \n",
    "    # create a figure and make the plots\n",
    "    fig = plt.figure(figsize=(14,8))\n",
    "    gs = gridspec.GridSpec(1, 2, figure=fig)\n",
    "\n",
    "\n",
    "    ax81 = fig.add_subplot(gs[0,0], projection='3d')\n",
    "    ax82 = fig.add_subplot(gs[0,1], projection='3d')\n",
    " \n",
    "\n",
    "\n",
    "    # colour maps\n",
    "    colours = ['cool', 'plasma', 'spring']\n",
    "\n",
    "    # plot the time embedding \n",
    "    cebra.plot_embedding(embedding=time_embedding[label_classes[0],:], embedding_labels=labels[label_classes[0],0],ax=ax81, markersize=size, title='Time embedding', cmap=colours[0])\n",
    "    cebra.plot_embedding(embedding=time_embedding[label_classes[1],:], embedding_labels=labels[label_classes[1],0],ax=ax81, markersize=size, title='Time embedding', cmap=colours[1])\n",
    "\n",
    "\n",
    "    # plot the behaviour embedding \n",
    "    cebra.plot_embedding(embedding=behaviour_embedding[label_classes[0],:], embedding_labels=labels[label_classes[0],0],ax=ax82, markersize=size, title='Behaviour embedding', cmap=colours[0],)\n",
    "    cebra.plot_embedding(embedding=behaviour_embedding[label_classes[1],:], embedding_labels=labels[label_classes[1],0],ax=ax82,markersize=size, title='Behaviour embedding',  cmap=colours[1])\n",
    "\n",
    "    gs.tight_layout(figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1717,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the classes\n",
    "lr_classes = [left,right]\n",
    "lr_classes[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(t_embed, b_embed,lr_licks, lr_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try this with the infoNCE setting -- maybe the behaviour embedding will make sense then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual NMs\n",
    "\n",
    "Now let's see how well the individual NMs capture the left/right choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of formatted array: (218572, 1)\n",
      "shape of formatted array: (218572, 1)\n",
      "shape of formatted array: (218572, 1)\n",
      "shape of formatted array: (218572, 1)\n"
     ]
    }
   ],
   "source": [
    "individual_nms = cp.individual_datasets(traces_=traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural tensor shape:  torch.Size([1717, 20])\n",
      "reward labels shape:  (1717,)\n",
      "choice labels shape:  (1717,)\n",
      "rpe labels shape: (1717,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.1554 neg:  5.6496 total:  5.8050 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:12<00:00, 159.63it/s]\n",
      "pos:  0.0003 neg:  6.2380 total:  6.2383 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:12<00:00, 154.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED ANALYSIS OF NM 0: \n",
      "neural tensor shape:  torch.Size([1717, 20])\n",
      "reward labels shape:  (1717,)\n",
      "choice labels shape:  (1717,)\n",
      "rpe labels shape: (1717,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.0005 neg:  6.2362 total:  6.2367 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:13<00:00, 150.68it/s]\n",
      "pos:  0.1276 neg:  6.0913 total:  6.2189 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:14<00:00, 134.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED ANALYSIS OF NM 1: \n",
      "neural tensor shape:  torch.Size([1717, 20])\n",
      "reward labels shape:  (1717,)\n",
      "choice labels shape:  (1717,)\n",
      "rpe labels shape: (1717,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.3709 neg:  5.4750 total:  5.8459 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:14<00:00, 137.77it/s]\n",
      "pos:  0.0002 neg:  6.2381 total:  6.2383 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:18<00:00, 106.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED ANALYSIS OF NM 2: \n",
      "neural tensor shape:  torch.Size([1717, 20])\n",
      "reward labels shape:  (1717,)\n",
      "choice labels shape:  (1717,)\n",
      "rpe labels shape: (1717,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos:  0.1615 neg:  5.4783 total:  5.6397 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:13<00:00, 146.71it/s]\n",
      "pos:  0.0001 neg:  6.2382 total:  6.2383 temperature:  1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:14<00:00, 136.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED ANALYSIS OF NM 3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b_embeds, t_embeds, t_labels, [positive, negative] = cp.nm_analysis_2(individual_nms, df_trials_ses, trace_times, choice_times, title=\" \",label='choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, sds = cp.get_auc(b_embeds, t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5016057788481418, 0.7046652101272329, 0.5, 0.5]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make function to make the plots given a list of embeddings\n",
    "def plot4_embeddings(embeddings, labels , l_class, means=None, titles=['DA only', 'NE only', '5HT only', 'ACh only'], t=\"\"):\n",
    "\n",
    "    # number of plots\n",
    "    n_plots = len(embeddings)\n",
    "\n",
    "    n_columns = 2\n",
    "    n_rows = n_plots//n_columns\n",
    "\n",
    "    # create axis\n",
    "    fig = plt.figure(figsize=(8,4*n_plots))\n",
    "    gs = gridspec.GridSpec(n_rows, n_columns, figure=fig)\n",
    "\n",
    "    # colour \n",
    "    c = ['cool','plasma','pink','winter']\n",
    "\n",
    "    for i, embed in enumerate(embeddings):\n",
    "\n",
    "        # create the axes\n",
    "        ax = fig.add_subplot(gs[i // n_columns, i%n_columns], projection='3d')\n",
    "\n",
    "        ax.set_xlabel(\"latent 1\", labelpad=0.001, fontsize=13)\n",
    "        ax.set_ylabel(\"latent 2\", labelpad=0.001, fontsize=13)\n",
    "        ax.set_zlabel(\"latent 3\", labelpad=0.001, fontsize=13)\n",
    "\n",
    "        # Hide X and Y axes label marks\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "        ax.yaxis.set_tick_params(labelleft=False)\n",
    "        ax.zaxis.set_tick_params(labelright=False)\n",
    "\n",
    "        # Hide X and Y axes tick marks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "\n",
    "\n",
    "        if means.any():\n",
    "            titles=['DA only, AUC:{}'.format(means[0]),'NE only, AUC:{}'.format(means[1]), '5HT only, AUC:{}'.format(means[2]), 'ACh only, AUC:{}'.format(means[3])]\n",
    "\n",
    "\n",
    "        # plot the embedding\n",
    "        cebra.plot_embedding(embedding=embed[l_class[0],:], embedding_labels=labels[l_class[0]], ax=ax, markersize=2,title=titles[i], cmap=c[0])\n",
    "        cebra.plot_embedding(embedding=embed[l_class[1],:], embedding_labels=labels[l_class[1]], ax=ax, markersize=2,title=titles[i], cmap=c[1])\n",
    "\n",
    "    plt.suptitle(t, fontsize=15)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.7, 0.5, 0.5])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(means,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot4_embeddings(b_embeds, t_labels, [positive, negative], means=np.round(means,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
